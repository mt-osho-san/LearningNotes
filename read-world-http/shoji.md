# 1 章　ブラウザは何をしているのか

- 基本的な HTTP のリクエスト、レスポンス内容についての解説をしている
- HSTS のデータベースがあることを知らなかった
  - HSTS 自体は http ヘッダに Strict-Transport-Security の項目を定義することで次回以降 https での通信をさせる
    - 初回は平文での通信になってしまう
  - HSTS のデータベース（リスト）というのは、正式には HSTS Preload というもので、そのリストに該当するページは初回アクセス時から https での接続をさせる仕組み
    - 主要ブラウザはほぼ対応している

---

# 2 　章　

- この章では HTTP/1.0 ができるまでの歴史と、HTTP/1.0 におけるメソッドやパスなどについて解説をしている
- HTTP/0.9 という名前ができたのは、HTTP/1.0 ができてからだったのか
- MDN はもともと Mozilla のものだったが、現在は Google や MS もコントリビュートしている
- HTTP/0.9 では、HTML 以外を送る想定がなかったり、新しい文書に更新したり、削除したりできなかった
- http ヘッダーの"x-"は私的な独自ヘッダーに利用しているが、「標準外のフィールドが標準になったときに不便が発生するため、2012 年 6 月の RFC 6648 で非推奨になりました」らしい
- メールとニュースグループは HTTP の祖先のようなもので、それぞれ MIME やフィールド、メソッドやステータスコードが受け継がれている
- canon が.canon のトップレベルドメインを持っているのか、canon は IT のイメージあまりなかったが当時は進んでいたのか？（google で canon 調べると canon.co.jp だった）
- キリル文字の і とローマ字の i など似た文字を使った攻撃をホモグラフ攻撃というらしい、名前あったのか
- dk 社もスパルタン仕様

---

# 3 章

- HTTP/1.0 の主にブラウザ側での動きを解説する。
- フォームの機能を使ってファイル送信を-d のかわりに-F とすることで実現可能
- サーバーからブラウザへの通信時の gzip などの圧縮はサーバー側で設定が必要？
  - もしくは特に設定せずとも圧縮している？
- セッションクッキーと永続クッキーの 2 つがあることを知らなかった
  - 永続クッキーはいつまで残るのか
  - ＝＞"Cookie に期限日が含まれていない場合は、セッション Cookie と見なされます"
  - デフォルトはセッションクッキーということか
- クッキーはリクエスト時に毎回付与されるので適切なサイズ、量のクッキーを使うことが通信容量の観点で良い
- localStorage, sessionStorage は同一オリジンでのみ利用可能なのですね。
- ベーシック、ダイジェスト認証のデメリット
  - リクエストごとに認証が必要、明示的なログオフができない、端末の識別ができない
- 代わりにフォームのログインとクッキーを使ったセッション管理を利用するケースがほとんど
  - ダイジェスト認証とは違い、ID、PASS を直接サーバーに送信するので SSL/TLS が必須
- 署名付きクッキーでデータの一時的な保存
  - サーバー側にデータ保存のしくみが必要ないが、クライアントが別々のデバイスから利用したら共有されない
  - 安易に使うとユーザビリティが悪くなりそう
- なにかの勉強で x-forwarded-for ヘッダの話があった気がするが、Forwarded で標準化されているのか
- Last Modified（更新日時によるキャッシュ）はキャッシュの利用を確認するためにもサーバーへのアクセスが必要なので、Expired が導入された
  - 地球の裏側だとキャッシュの確認だけで 0.2 秒、光の速度を感じる
- Cache control の max-age, private などでキャッシュを利用するかどうかを制御可能（HTTP/1.1~）
- Vary ヘッダーの存在は聞いたことがなかった
  - ユーザーやデバイスによって表示内容が変化する際の理由を示している
- Referer スペルミスなのか笑（Referrer が英語としては正しい）
- Referer でアクセス元の URL がわかるので、機密情報を GET パラメータにいれるのは良くない
- robots.txt のほうが優先されるが、meta タグのほうが細かい調整が可能（noindex, nofollow など）
  - robots.txt を知っていて設定しない場合はクロールされても何も言えない
- サイトマップ：ウェブサイトに含まれるページ一覧とそのメタデータを提供する XML ファイル
  - サイトマップって聞いたことあったがしらなかった
- Google のガイドライン「同一コンテンツをすべてのブラウザに配信し、必要な設定を選ばせるレスポンシブデザインが推奨」
  - user-agent で表示内容を変えるもんかと思っていたが、推奨ではないということか

# 5 章

- HTTP/1.1 以降の機能について紹介
- 主な変更点として、通信の高速化、TLS による暗号通信、新メソッド追加など
- 以前は毎回コネクションを張るためにハンドシェイクをしていたが、keep-alive はこれを削減することで、通信速度の向上
  - ブラウザの同時接続数の推奨値が 4 => 2 に下がるというのはどういうこと？
  - ブラウザ１つに対して４つくらい接続していないと通信が遅いということ？
  - 接続を切るにはヘッダに Connection: Close を付与するか、タイム・アウトするか
  - 持続時間はクライアント、サーバー両方もっており、Frefox115s, nginx75s, apache15s
- パイプライニングはレスポンスを待たずにリクエストを送るというものだが、対応していないサーバーが多かったり、レスポンスの順序が大事なのっで HoLB が発生したりで、使われることはほとんどなくなった
  - が、HTTP/2 でストリームという機能として生まれ変わった（@ 8 章）
- アルゴリズムを秘密にするのではなく、アルゴリズムを公開しても暗号化ができることが大事
- TLS は接続の確立時に公開鍵暗号を使って共通鍵を作る。それ以降は共通鍵で通信をすることで安全性とスピードの両立
- 最も長い場合の TLS 接続にかかる RTT
  - TCP で 1.5, TLS ハンドシェイクで 2RTT, HTTP のリクエストで 1RTT => 計 4RTT (TCP の最後と TLS の最初は一緒にできる)
  - この往復を減らすために keep-alive やセッション再開機能、PSK などがある
- 鍵交換の方法、暗号化、署名方式などをまとめて暗号スイートという
- TLS はサーバークライアント間が信頼できない通信路でも安全、一方でブラウザ上のクラッキングなどは対処できない
- サーバー経由でクライアント同士がチャットする仕組みもがあるのか（この場合はサーバーの中は秘匿されない）
  - どういうアプリで使うのか
- ACME プロトコル初めて聞いた（自動証明書管理環境）
  - Let's Encrypt の無料の証明書サービスで利用されている
- 証明書の種類の話セキスペであったなあ
  - 今はもうブラウザ上での表示がかわることはないのか（TLS かどうかしか気にしない）
- 1.1 では PUT と DELETE, Options, trace, connect, path が追加された
  - Options は利用可能なメソッドを返す、が多くのサーバーでは有効にされていない
  - connect は HTTP のプロトコル上に他のプロトコルのパケットを流せる（主に HTTPS を中継する目的で使われる）
- アップグレードは、HTTP から別のプロトコルへアップグレードできる機能
  - HTTP ＝＞ TLS、Websocket、HTTP2 へ
  - 現在はそもそも TLS 前提なので HTTP2 では削除されている機能
- チャンクはデータを一括で送るのではなく、小分けにして行う。
  - 生成 AI で使われる＝＞ WebSocket だと思っていた
- データ URI スキームでは、URI がデータそのものになる

# 6 章

- HTTP/1.1 の時代になると、HTML を取得するだけのプロトコルから汎用的な用途に変化していった。
  - 本性では 1.1 以降に拡張されたプロトコルや規約を使った様々な事例を紹介
- Content-Disposition フィールドの指定によって、ブラウザで表示するのか、ダウンロードするのかを変える
- a タグで、downdload を指定すると、クリックした際にダウンロードするように矯正可能
  - マルウェアをダウンロードさせるのにも使われそう
- 複数範囲のユースケースは、キャッシングされていない部分だけ取得するとか、大きなファイルを順次ダウンロードするなどで利用される
  - キャッシュされている部分がどこかってどうやって確認してるんだろうか
- JS の XMLHttpRequest は、XML はほとんど関係ないが XML 処理用ライブラリにいれるための言い訳として XML がついている
- Form と比べると、送受信時に HTML がロードされないことや、キーと値が 1:1 になっている必要がないため様々なフォーマットで送受信可能だったりする
- 既存の仕組みで双方向通信できるようにしたのが Comet、WebSocket では最初からそれを想定して作られた
- HttpOnly 名前ややこしい、HttpOnly はクライアントのスクリプトからアクセスできなくする、Secure は HTTPS 通信の場合のみ Cookie が利用可能
- GeoLocation はクライアントが計測する方法と、サーバー側で推測する方法がある
  - skyhook の自動車走らせる方法は、後から追加されたアクセスポイントは対応していないってこと？
  - radiko は、Chrome 拡張機能で現在位置を変更できるものがある。
- RPC は、別のコンピュータの機能をあたかも自分のコンピュータ内であるかのように呼び出しを行う方法
- SOAP は HTTP の中に見に HTTP のような SOAP ヘッダ、SOAP ボディという構造を持つ。
  - SOAP は可搬性を重視するあまり複雑度が増してしまった
  - JSON-RPC はシンプルさを重視して、コンパクトにしている
  - この辺の技術は今はほとんど使われていないもの？
- WebDAV は HTTP を拡張して分散ファイルシステムとして使えるようにしたもの
  - 同期型であり、ネットワークがなければファイル一覧を取得できない（GDrive などはローカルにコピーを持っていて、必要に応じて同期）
- ケロベロス認証：ID とパスワードで AS から TGT をもらう。TGT を使って各サービス用チケット発行
  - 主に Windows で利用されて、ドメインへの参加が必須
- 現在は OIDC がデファクトスタンダード
- JWT：JSON をベースにして改ざん防止の署名を加えたもの。汎用的な仕組みだが、認証認可でよく使われる
- ヘッダー、ペイロード、署名をピリオドで接合したもの
- 意図的に署名アルゴリズムを none に上書きされないようにしないと、セキュリティホールになる
- Google Photo の共有機能は 40 字の英数字で、10 奥人のユーザーが１万枚ずつ入れても、1 ０の 58 乗書いアクセスすると１枚くらいだれかの写真を見れるというくらい
  - とはいえずっと同じ URL を使うと漏洩のリスクがあるので、期間限定するなど必要
- セキュリティホールを発見したときには securiy.txt から連絡先を見つけて報告（一般に公開されると攻撃に使われる）
- 短縮 URL や QR コードは基の URL を隠蔽するので注意が必要

# ７章

- エラーが出る

```
openssl req -new -sha256 -key ca.key -out ca.csr -config ./read-world-http/chapter4/openssl.cnf
Can't open "./read-world-http/chapter4/openssl.cnf" for reading, No such file or directory
```

- クライアント認証のユースケース意識したことなかったが、DC 内の通信や IoT などで使われるのか。
- チャンクは go の場合、最初からサポートされているので意識せずに利用できる。

# 8 章

- ALPN では TLS ハンドシェイク後に利用可能なプロトコルを共有してプロトコルを選択
- ALPN では TCP コネクションを再利用するので、UDP の HTTP3 は利用できない
  - そこで HTTP Alternative Services は同一サービスが別オリジンで動作していることを示して、そちらに誘導することで UDP を利用できるようにしている
- DNS の HTTPS レコードは、接続開始時点から利用可能なプロトコルを DNS レコードとして返せるので、より早い時点でプロトコルが決定する
- HTTP2 の前身は SPDY で Google が作成した
  - Google は Web サービスとブラウザの両方を抑えているので大規模な検証が可能
- HTTP2 の改善点は次の通り
  - ストリームにより、バイナリデータを多重に送受信可能
  - フィールドの圧縮
- ストリーム
  - HTTP1.1 まではひとつのリクエストが TCP ソケットを占有するので、ひとつのオリジンサーバーに対して 2~6 の接続を使っていたが、ストリームでは１つの TCP 接続の内部に仮想の TCP ソケットを作成し、利用。
- HTTP1.1 はフィールドの終端を見つけるまで逐次読み込んでいたが、HTTP2 ではバイナリ化されており、レスポンスの戦闘にフレームサイズが入っているので、受信側の TCP ソケットのバッファをすばやく空にできるのですぐに次のリクエストが可能
- フローコントロールによって、ストリームの通信料制御を行い、処理速度差が大きい機器間でデータを送りすぎることを予防する
- プリロード：link タグ、link ヘッダーフィールドによって HTML 本体をダウンロードする前に関連リソースのダウンロードが可能。
- HPACK：フィールドの圧縮方式、フィールドでは決まった名前や結果がよく出るので辞書として持っておく。
- SPDY が HTTP2 になったように、HTTP3 は QUIC が前身。
- HTTP2 は TLS なので高機能だが、パフォーマンスは落ちる。
  - HTTP3 では UDP を使うことで、アプリ層で TLS の機能を賄っている。（ネゴシエーション、輻輳制御など）
  - それにより、初回でも 1 往復の通信でネゴシエーションしたり、再接続では 0RTT で再送できる
  - HTTP2 では TLS と重複していた機能があったが、これを簡略化している。
- 従来はモバイル通信と WIFI が切り替わったりすると、5tuple によって別のコネクションとして認識されてしまうが、QUIC では通信経路が変わってもコネクション ID が維持される。
- HTTP2 からの変更はストリーム ID が 31->62 ビットに増えて上限まで使い切って切断されるリスクが減った、各フレームがストリーム ID とフラグを持たなくなったなど。
- HTTP3 ではサーバープッシュやストリームの優先度といったほとんど使われない機能の削除もされた。
- JS 用の通信 API
  - Fetch API:CORS の取り扱いが制御しやすい、キャッシュの制御可能、送受信ともストリーム可能
  - Server-sent Events：HTML5 の機能ひとつ、サーバーから任意のタイミングでクライアントにイベントを通知できる
  - WebSocket: オーバーヘッドの小さい双方向通信を実現、相手が決まってるので送信先などの情報は持たない（ステートフル）
  - WebRTC:ブラウザーサーバー間だけでなく、ブラウザ同士の P2P でも使われる。主に UDP が使われる。
    - ユースケース：ビデオ通話システム、スクリーン共有、ファイル交換、IP 電話端末、
  - Web Transport：WebSocket の弱点をカバーしている（非 TLS 通信を行う可能性がある、HoL ブロッキングがある）
  - HTTP ウェブプッシュ：ウェブサイトで通知機能を提供する仕組み（送った時点でブラウザが起動していなかったり、オフラインでも通知を遅れる）
    - Service Worker というサーバーとブラウザの間にあるプロキシサーバーのようなものを使う。
