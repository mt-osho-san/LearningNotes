# Real World HTTP

## 1

- スキーマ、ホスト名、パス、ハッシュはどれがどれか忘れがち
- ヘッダーは仕様上フィールドと呼ぶらしい(知らなかった)
- Referer はブラウザが勝手につけるもの？
  - サーバーサイドじゃないよな

## 2 HTTP/1.0 の世界:基本となる 4 つの要素

- いろんな歴史の話
- いろんな組織があるんだな〜という感じ
- MDN が Mozilla ってのは知っていたけど、Google や MS もコントリビュートしているのは知らなかった
  - 事実上のブラウザの標準みたい
- HTTP/0.9 では HTML 以外を送る想定がなかったり、ステータスを返すこともできなかった
- ヘッダーに X をつけると独自ヘッダーとして定義できるのは知らなかった
  - X-xxxx みたいなやつはよく見かけていたから理由がよくわかった
- ヘッダーの Key 値はライブラリによって正規化の方法が変わるのはなんとなくそんな気がしてたけど実際に知れてよかった
- Content Sniffing はお節介だったってことか
  - X-Content-Type-Options: nosniff はよくみるが、今ではおまじないレベルって感じか
- 3xx 版のステータスはリダイレクトの意味と思っていて、それはあっているけど、もっと抽象的にいうとサーバーからの命令って書いてあって、なるほどなーと感じた
- 999 ステータスコード知らなかった
  - お茶目すぎ
  - 429 でいいやん
- リダイレクトの回数に制限をなくしたがブラウザ側で無限ループを検知して止める責務が追いやられているのは知らなかった
- ヘッダーやクエリは複数同じ key を使ってもいいけど、どうパースされるかはフレームワーク次第はまじで鬱陶しい
  - go は同じ key を複数使うと配列
  - rails は同じ key を複数使うと最後の値だけ評価される
    - 配列にしたいなら `key[]=value1&key[]=value2` みたいにする
      - 若干 rails は違和感
- テキストにマークしてリンクに情報を含めるのはよくやるけど、これは URL フラグメントテキストディレクティブっていうんだ
- 国際化ドメイン名とエンコーディングルール Punycode は初めて知った。こんなことできるんや
- URL にめちゃめちゃクエリとかついているのはバックエンド側で統計とか取っていることがあるから説は面白い
  - そのため、ノイズがないようにバックエンド側は正規 URL を好むってのも面白い
- curl で-d @FILE_NAME でファイルの中身を body として送れるのは知らなかった
- 前の URL の 2000 文字制限のために Elasticsearch は GET で Body を受け取るの知らなかった

  - ただ、前の説明でもあるように GET で Body は送れないようにした方が良いし受け取らないべきだと思う

- ヘッダーではなくフィールドと呼ぶべきだったり、URL や URI が混ざったりと標準化ってやっぱり難しいなと思った

## 3 HTTP/1.0 のセマンティくす:ブラウザの基本機能の裏側

- x-www-form-urlencoded の細かい仕様は忘れたら見返したい
  - 一応 OAuth の仕組みでも使うことがあるので、JSON でのやりとりが主要ではあるものの、知っておくと便利だと感じた
- multipart/form-data はファイルのアップロード時に使うっていう話は知らなかった
- 様々なメタデータを送ることができるので、ファイルデータは multipart/form-data でしか送れないってのは初しり

  - json しかほとんど送らないからここら辺は疎い

- ランダムな区切り文字で複数データを渡せるらしい

- Accept とかのフィールドはコンテントネゴシエーションっていうんだ
- Cookie って GDPR だと基本ユーザーに同意を取らないといけないものだと思ってたけど、厳密に必要なクッキーは別に同意なしでいいのか
- なので、認証情報などは別にユーザーの同意なしに送っていいってことか?
- また、ショッピングカート機能みたいなシステム上必要なものは OK らしい
- Cookie に 4kb の制限(推奨値？)があるのは知らなかった
- Cookie の属性はセキスペでよくやったなーという感想
- いつも思うけど、CORS って必要？
  - 他サイトからのリクエストを防げるのは利点に見えるけど、サイトじゃなくて悪意のあるリクエストを curl とかで送れば良くない？それは CORS 防げないし。と思う
  - また調べよ
- Basic 認証と、Digest 認証は今ではあまり使われないらしい
  - Basic 認証はなんだかんだ GitHub の認証付きリクエストや OAuth のクライアントシークレットフローで使われていると思う
  - あとはエンタープライズ企業の古システムでは使われていて、エンプラ向けにシステム作成するのであればサポートしないといけないってこともある
- 電子署名を使ってサーバーサイドに認証情報を持つのではなく、クッキーだけで認証させるのはなるほどという感じ
  - 署名使えば公開鍵だけで検証できるのいいよなという感じ
- 304 Not Modified はなんとなくみたことあるけど、しっかり理解できた
- 確実にキャッシュしない条件があるのは知らんかったのでこの項目は今後のリファレンスにしたい
  - これで思ったんだけど、通信全部 POST でよくない理論は、キャッシュのことを考えるとよくないかも
  - もし POST でキャッシュしたくなるのであればそれはアプリケーションのロジックで行わないといけなくなる
- ETag は便利そうだと感じた。Expires よりも正確にキャッシュを制御できる気がした
- Cache-Control ヘッダーもよく見るがよくわかってなかったのでみれてよかった
  - サーバーからクライアントへのキャッシュに対する指示
  - public の説明で言う、同一のコンピュータってクライアントのコンピュータ？それともサーバーのコンテンツ？
  - 多分前者っぽい
  - immutable は強気すぎんか？変化しないこととかある？path ごとにコンテンツを変えるものであればなくはないか。ただ非標準
    - no-cache はキャッシュを使わないではなく、更新があるかどうかをサーバに聞きにいくってのはわかりにくい
- キャッシュは便利な一方、ここまでキャッシュに対する条件分岐があると、キャッシュが関係するかもしれない障害対応の切り分けをする際に大変そう
- あと、通信が繋がらない〜＞つながるになった時原因は違うにも関わらずキャッシュのせいにしがちになる気がするし、実際なっている
  - キャッシュの昨日をちゃんと把握して本当にキャッシュの成果どうかは判断できるとかっこいいかも
  - あとは、キャッシュはブラウザだけじゃなく様々なコンポーネントが持ちうる可能性があるのがだるい
- Vary ヘッダーは表示が変わる理由を示すもので、これによって正確にコンテンツをキャッシュさせることができる
  - 検索エンジンのヒントにも使われるらしい
  - Vary があることでクライアント毎に良い検索結果をエンジンが返してくれる感じ
- クローリング時は robots.txt を守りましょう！また、コンテンツを出す側も robots.txt を書いとかないとクローリングされても文句は言えない
- robots.txt はブラックリスト的だが、サイトマップはホワイトリスト的な仕組み

- 感想としては、あまりここら辺は気にせずともアプリケーション作れているのでフレームワークって相当偉大だなと思ったし、アプリケーション作るのであればフレームワークを使うべきだと感じた
- もしくは JSON 返すだけの API サーバーが楽な気もする
- API サーバーであれば API Gateway などのマネージドな仕組みを前段に置いておくといろいろ共通の処理やセキュリティの対策が楽になるので、そういったものを使うべきだと感じた

## 5 HTTP/1.1 のシンタックス:高速化と安全性を求めた拡張

- HTTP/1.1 はめっちゃ長生きしてるな
- Keep-Alive は TCP コネクションを使い回すって感じかな
- HTTP/2 では常時 Keep-Alive でヘッダーに含めてはいけないのは知らなかった
- パイプライニングは不遇

  - 理由的にはうまく実装されていないサーバーが多いからって感じはしたが、並列に送信してもその順番で返さないといけないのは確かに時間節約効果が薄くなりそう
  - HTTP/2 では改良されたストリームに変わっているみたい

- TLS は様々なプロトコルに使える！(これが層に分ける仕組みよな)
- セキュリティ関連の技術は技術選択肢が 1 つだけという状態を禁じる慣例があるのは知らなかった
  - 確かに一つしかなくて、それがやられたら終わりなので理には叶っている
- DHE はいつもわからん。。。知っている値が多すぎて中間者でも乗っ取れるのでは？と思ってしまう
- 公開鍵が共通鍵に比べて 15000 倍も遅いのはびっくりした

  - IT の世界は人間の感覚では全部処理が高速すぎてこういうのちゃんと見ないと知らない間にボトルネックになっているんだろうな〜という気持ち

- X.509 は至る所で利用されているイメージ。ここら辺知っておくのはエンジニアとして重要そう
- Session や Keep-Alive のおかげでだいぶ通信の効率がよくなった
  - 命令セットのレベルで AES を高速化するのはすごい
  - HTTP/2 ではセッション数が最大で 1/6 で、TLS1.3 ではハンドシェイクの数も減っているらしい
- 暗号強度を上げると計算負荷が高まって、DoS に弱くなるってのは確かにと思った
- TLS が守るもの、はまとまっててみんな読むべき笑
- ACME プロトコルは楽で良い。もう少し詳しく知りたい技術の一つ
- EV 証明書のアドレスバー意味ない説は面白い
- PUT,DELETE 追加の話で、HTML のウェブフォームからはこれらのメソッドは利用できないのは知らなかった
- HTTP メソッドはプリミティブな操作だけど、HTTP はドキュメントを扱うさらに上位な API という違いがあるのは確かにそうだなと思った

  - HTTP メソッドを発行した後のことは HTTP では隠蔽して、より抽象度の高い結果を返す、HTTP 自体は一回のやりとりで完結する
  - まあ、ここら辺は 思想の話なので、仕様上そういうものっていうわけではなく、そう作った方がいいよねという話だと思う

- OPTIONS メソッドの役割がそのサーバが利用できるメソッドを知らせるものっていうのは知らなかった
  - CORS の時に Preflight で問い合わせるものっていう認識だった
- 基本は OPTIONS は閉じられているらしい
  - おそらくセキュリティのためかな
- TRACE メソッドはリクエストの内容をそのまま返すようなメソッドが非推奨メソッドらしい

  - XST というクロスサイトトレースの脆弱性があるから
  - XST は TRACE によってクッキー情報などを盗む攻撃
  - Cookie は基本的に HttpOnly や SameSite などの属性によって守れているが、TRACE によって返却されるレスポンス情報はただのバイナリかつ、そこに Cookie 情報が含まれているので、それを盗むことができる
  - おもろい！

- CONNECT で HTTPS 以外は拒否するというくだりはよくわからない

  - 何を強調したい？
  - 前職で Proxy と戦い続けたことを思い出す。。。

- PATCH メソッドはリソースの部分的な更新を行うメソッド

  - PUT はリソース全体を更新するメソッド
  - ここまでちゃんと区別するのは HTTP の思想であるドキュメントに対する操作の抽象度を漏洩してない？？
  - PATCH なのか PUT なのかはアプリケーションの設計次第って感じかな？
  - ただ、メソッドごとにハンドラーを設けておけば、操作が違う場合、同じメソッドないで処理を分岐させるよりもわかりやすいかもしれない
  - あと GPT さんに聞いたら冪等性の話が出てきた
  - PUT は冪等性を担保するべきだが、PATCH は冪等かどうかはわからないとのこと
    - PUT ではマルっと置き換えるが、PATCH では部分的に変更するので、例えばある値をインクリメントするという操作が PATCH には実装でき、冪等性を担保できないみたいな感じ

- HTTP/1.1 からは HTTP 以外へのプロトコルのアップグレードができるらしい
- クライアントからでもサーバからでもアップグレードを要請できる
- 種類は以下

  - HTTP から TLS を使った安全な通信へのアップグレード
    - これは RFC2817 で説明されているもので、これをやってもセキュリティ敵に守られない可能性があるみたい
    - HTTPS とは違うってこと？
      - 暗号化をするのが HTTP の前か後かみたい。このアップグレードは HTTP をした後にアップグレード
    - 今は TLS そのものが持つハンドシェイク時のプロトコル選択(ALPN)を使うことが推奨されており、HTTP/2 ではこのプロトコルのアップグレード機能が削除されているらしい
  - HTTP から WebSocket へのアップグレード
  - HTTP から HTTP/2 へのアップグレード

- クライアントからのアップグレード要請は Upgrade,Connection ヘッダーを使う
- Upgrade 可能か知るためにまず OPTIONS メソッドで確認する
  - でも OPTIONS は基本閉じられているんじゃなかったけ？
  - 確認できなかったら Upgrade はやめるんかな？
- サーバ側からはステータスレコード 426 をつけるらしい
- TLS 通信への切り替えはリダイレクト機能とか使おうねとのこと

- バーチャルホストは便利
- チャンク送信の Body 部に対して詳しくなれた
  - 最後に 0 だけのチャンクを送ることで終了を示す
- ブラウザからアップロード方向の通信でチャンク送信を使えないのはなんで？
  - 一応頑張ればできるっぽいけど、標準の方法じゃないからクライアント、サーバともに頑張る必要はありそう
- Trailer で指定したヘッダは最後に送信できる

- Expect: 100-continue は知らなかった。100 Continue が返ってきたら受け入れ可能とのこと
- 無理だったら 417 Expection Failed とのこと
- 実は curl はよしなにやってくれていたとのこと
- データ URI スキームによってデータそのものを表現できるので、画像をそのままデータとしてツッコで、解釈できるようにするものらしい？
  - 画像をそのままデータとして埋め込むことで、リクエストを減らすことができる
  - ただ、一回のデータ総量は多くなるよな？というところ
  - これ使わない方が画像以外はすぐにレンダリングされてそれはそれでいい場合がある気がする
